# ğŸŒ¿ Plant Disease Detection using CBAM-ResNet34

This project is a deep learning-based classifier designed to detect plant diseases from leaf images using a modified ResNet-34 architecture enhanced with CBAM (Convolutional Block Attention Module). It combines two popular datasets â€” **PlantDoc** and **PlantVillage** â€” to build a robust image classification model.

---

## ğŸ“¦ Datasets Used

* **PlantDoc**: Real-world dataset with \~2.6k noisy, variable-quality leaf images across multiple crops.
* **PlantVillage**: Benchmark dataset with over 54k high-quality, labeled plant disease images.

> We combined both datasets and split them into training (80%), validation (10%), and test (10%) sets with class balance preserved.(**Not Combined here as during the training the Google colab's Compute units were not suffcient for such huge traning**)

---

## ğŸ§  Model Architecture

* **Backbone**: ResNet-34 pretrained on ImageNet
* **Attention**: CBAM (Channel and Spatial Attention)
* **Classifier**: AdaptiveAvgPool2D â†’ Dropout â†’ Fully Connected â†’ Softmax
* **Total Number of Trainable Params: 21,385,955 (21M)**
* **Estimated Total Size (MB): 181.46MB**

---

## ğŸ”¥ Performance Overview

| Metric         | Score (Before Combining Datasets) |
| -------------- | --------------------------------- |
| Train Accuracy | > 90%                             |
| Val Accuracy   | \~67% (overfitting observed)      |

### âš ï¸ Overfitting Analysis

Initially, the model trained only on PlantDoc showed signs of **overfitting**:

* Training accuracy soared to 90%+
* Validation accuracy stagnated at \~67%

### ğŸ§ª Improvements To be Made(if more compute power available)

* âœ… Added **PlantVillage** dataset to increase data volume
* âœ… Introduced **extensive data augmentation**
* âœ… Applied **Dropout** and **L2 regularization**
* âœ… Implemented **stratified splitting** to maintain class balance
* âœ… Enabled **early stopping** and **checkpointing**

---

## ğŸ“Š Final Project Structure

```
project-root/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ PlantDoc/
â”‚   â”‚   â”‚    â”œâ”€â”€ PlantDoc-Dataset/
â”‚   â”‚   â”‚    â”‚           â”œâ”€â”€ train
â”‚   â”‚   â”‚    â”‚           â”œâ”€â”€ split train
â”‚   â”‚   â”‚    â”‚           â”œâ”€â”€ test
â”‚   â”‚   â”‚    â”‚           â”œâ”€â”€ val
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base_cnn.py
â”‚   â”œâ”€â”€ model summary.txt
â”‚   â”œâ”€â”€ efficientnet_b3                         
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ dashboard.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ transforms.py
â”‚   â””â”€â”€ download_datasets.py
â”œâ”€â”€ cams/
â”‚   â”œâ”€â”€ images
â”œâ”€â”€ train.py
â”œâ”€â”€ eval.py
â”œâ”€â”€ gradcam.py
â””â”€â”€ requirements.txt
```

---

## ğŸ–¼ï¸ Grad-CAM Visualization

Use `gradcam.py` to visualize which parts of the image the model focuses on when making predictions.

```bash
python gradcam.py --image-path sample.jpg --checkpoint checkpoints/best_model.pth
```

---

## ğŸ§ª Inference

Run batch predictions with human-readable class labels:

```bash
python inference/predict.py --dir test_images/ --checkpoint checkpoints/best_model.pth
```

---

## ğŸ’¡ Future Improvements

* ğŸ” Try **lighter backbones** like MobileNetV3 for mobile deployment
* ğŸ§  Fine-tune with **class-weighted loss** to handle class imbalance
* ğŸ§¾ Add **metadata-based features** (location, humidity) for richer context
* âš™ï¸ Integrate with a **real-time webcam/detection dashboard**

---

## ğŸ“Œ Credits

* PlantDoc by M. H. M. H. B. et al. (CVPRW 2020)
* PlantVillage by Hughes and SalathÃ© (arXiv 2015)

---

> Made with ğŸ’š for sustainable agriculture and smarter farming
